{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# script template for creating conversations and uploading them to MongoDB\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, pipeline\n",
    "import pandas as pd\n",
    "from nlp import NLP\n",
    "import random\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# summarizer = pipeline(\"summarization\")\n",
    "\n",
    "# # OpenAI GPT-2\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "# model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# TRAIN_TEXT = \"\"\"One day I said to my self in my own thought ‘whom am I praying to or is  there  a  God  who  listens  to  me?’  At  this  thought  I  was  invaded  by  dead full sadness and I said: ‘In vain have I kept my own heart pure (as David says). Later on I thought of the words of the same David, ‘Is the  inventor  of  the  ear  unable  to  hear?’  and  I  said:  ‘who  is  it  thatprovided  me  with  an  ear  to  hear,  who  created  me  as  a  rational[being] and how have I come into this world? Where do I come from? Had  I  lived  before  the  creator  of  the  world,  I  would  have  known  the  beginning of my life and of the consciousness [of myself] that created me? Was I created by my own hands? But I didn’t exist before I was created. If I say that my father and my mother created me, then I must search for the creator of my parents and of the parents of my parents until they arrive at the first who were not created as we [are] but who came into this world in some other way without being generated. For if  they  themselves  have  been  created,  I  know  nothing  of  their  origin  unless I say, ‘he who created them from nothing most be an uncreated 2\n",
    "# essence  who  is  and  will  be  for  all  centuries  [to  come]  the  lord  and  master  of  all  things,  without  beginning  or  end,  immutable,  whose  years cannot be numbered.’ And I said: ‘Therefore, there is a creator; else there would have been no creation. This creator who endowed us with the gifts of intelligence and reason, cannot he himself be without them?  For  he  created  us  as  intelligent  beings  from  the  abundance  of  this intelligence and the same one being comprehends all, creates all,is  almighty.’  And  I  used  to  say:  ‘my  creator  will  hear  me  if  I  pray  to  him,’  and  because  of  this  thought  I  felt  very  happy.\"\"\"\n",
    "# prompt = summarizer(TRAIN_TEXT, max_length=250, min_length=30)[0]['summary_text']\n",
    "\n",
    "# inputs = tokenizer.encode(\n",
    "#     TRAIN_TEXT + prompt, add_special_tokens=False, return_tensors=\"pt\"\n",
    "# )\n",
    "\n",
    "# prompt_length = len(\n",
    "#     tokenizer.decode(\n",
    "#         inputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "#     )\n",
    "# )\n",
    "# outputs = model.generate(\n",
    "#     inputs, max_length=250, do_sample=True, top_p=0.65, top_k=40\n",
    "# )\n",
    "# generated = prompt + tokenizer.decode(outputs[0])[prompt_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Associate run to a project (optional)\n",
    "%env WANDB_PROJECT=huggingtweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_2 = GPT2LMHeadModel.from_pretrained(\"./data/output/quote/\")\n",
    "# tokenizer_2 = GPT2Tokenizer.from_pretrained(\"./data/output/quote/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = random.randint(0, 2**32-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTENCES = [\n",
    "    \"The epistemological limit of\",\n",
    "    \"The metaphysical realm of our\",\n",
    "    \"The moral structure inhrit\",\n",
    "    \"The ethical approach to\",\n",
    "    \"The ontological condition of\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = NLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, name_1 in enumerate(df.iloc[:,0]):\n",
    "    for j, name_2 in enumerate(df.iloc[:,0]):\n",
    "        if name_1 is name_2:\n",
    "            continue\n",
    "            \n",
    "        print(name_1, name_2)\n",
    "        \n",
    "        # INITIALIZE START PROMPT\n",
    "        print(df.iloc[j,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "\n",
    "for start in SENTENCES:\n",
    "    val = !python run_generation.py \\\n",
    "        --model_type gpt2 \\\n",
    "        --model_name_or_path output/$quote \\\n",
    "        --length 150 \\\n",
    "        --stop_token \"{'\\n'}\" \\\n",
    "        --num_return_sequences 3 \\\n",
    "        --temperature 1 \\\n",
    "        --seed $seed \\\n",
    "        --prompt {'\"' + start + '\"'}\n",
    "    generated = [val[-1-2*k] for k in range(3)[::-1]]\n",
    "    print(f'\\nStart of sentence: {start}')\n",
    "    for i, g in enumerate(generated):\n",
    "        g = g.replace('<|endoftext|>', '')\n",
    "        print(f'* Generated #{i+1}: {g}')\n",
    "        examples.append([start, g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # retrieve last run\n",
    "# project = %env WANDB_PROJECT\n",
    "# wandb_id = wandb.api.list_runs(project)[0]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Log results on our previous wandb run\n",
    "# wandb.init(id=wandb_id, resume='must')\n",
    "# wandb.log({'examples': wandb.Table(data=examples, columns=['Input', 'Prediction'])})\n",
    "\n",
    "# # Update display name\n",
    "# wandb.run.name = alltweets[0].author.name\n",
    "# wandb.run.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, name_1 in enumerate(df.iloc[:,0]):\n",
    "#     for j, name_2 in enumerate(df.iloc[:,0]):\n",
    "#         if name_1 is name_2:\n",
    "#             continue\n",
    "            \n",
    "#         print(name_1, name_2)\n",
    "        \n",
    "#         # INITIALIZE START PROMPT\n",
    "#         # print(df.iloc[i,1])\n",
    "#         # n = nlp.summarize(df.iloc[j,1])\n",
    "#         # conversation.append(n)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
