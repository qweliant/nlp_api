{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# OpenAI GPT-2\n",
    "tokenizer_gen = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model_gen = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "TRAIN_TEXT = \"\"\"The work of an intellectual is not to mould the political will of others; it is, through the analyses that he does in his own field, to re-examine evidence and assumptions, to shake up habitual ways of working and thinking, to dissipate conventional familiarities, to re-evaluate rules and institutions and to participate in the formation of a political will (where he has his role as citizen to play).\"\"\"\n",
    "prompt = \"Until this is user text\"\n",
    "\n",
    "inputs = tokenizer_gen.encode(\n",
    "    TRAIN_TEXT + prompt, add_special_tokens=False, return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "prompt_length = len(\n",
    "    tokenizer_gen.decode(\n",
    "        inputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "    )\n",
    ")\n",
    "outputs = model_gen.generate(\n",
    "    inputs, max_length=250, do_sample=True, top_p=0.95, top_k=60\n",
    ")\n",
    "generated = prompt + tokenizer_gen.decode(outputs[0])[prompt_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 250, but you input_length is only 84. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Until this is user text the subject must be of the highest general interest\" \"The work should be of interest to the reader\" \"In the case of the material that is available, the subject should be\"\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\")\n",
    "print(summarizer(generated, max_length=250, min_length=30)[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for person in list\n",
    "    for person2 i nlist\n",
    "        if person2 not person:\n",
    "            TRAIN_TEXT = \"\"\" \"\"\"\n",
    "            first = nlp.generate(TRAIN_TEXT, prompt)\n",
    "            prompt = nlp.summarize()\n",
    "            TRAIN_TEXT2 = \"\"\"  \"\"\"\n",
    "            second = nlp.generate(TRAIN_TEXT, prompt)\n",
    "            prompt2 = nlp.summarize()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "def modelin(actor_1,actor_2):\n",
    "    \"\"\"\n",
    "    generates a conversation between two actors\n",
    "    \"\"\"\n",
    "    nlp = NLP()\n",
    "    convo = {}\n",
    "    conversation = []\n",
    "    \n",
    "    # create initial text\n",
    "    text = nlp.generate(df.quote,\"\")\n",
    "    \n",
    "    # add text to list \n",
    "    conversation.append(text)\n",
    "    \n",
    "    # summerize text\n",
    "    prompt = nlp.summarize()\n",
    "    \n",
    "    # generate response from first question\n",
    "    text = nlp.generate(df.quote, prompt)\n",
    "    \n",
    "    # append response\n",
    "    conversation.append(text)\n",
    "    \n",
    "    i = 5\n",
    "    while i:\n",
    "        \n",
    "        # summerize text\n",
    "        prompt = nlp.summarize()\n",
    "        # generate next sequence training on generated text and prompt with summaryii\n",
    "        text = nlp.generate(conversation[-1], prompt)\n",
    "        conversation.append(text)\n",
    "        i-=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
