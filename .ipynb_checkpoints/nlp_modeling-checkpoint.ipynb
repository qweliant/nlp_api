{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, TFDistilBertModel, DistilBertConfig\n",
    "import tensorflow as tf\n",
    "distil_bert = 'distilbert-base-uncased' # Pick any desired pre-trained model\n",
    "roberta = 'roberta-base'\n",
    "\n",
    "# Defining DistilBERT tokonizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\n",
    "    distil_bert, \n",
    "    do_lower_case=True, \n",
    "    add_special_tokens=True,\n",
    "    max_length=128, \n",
    "    pad_to_max_length=True\n",
    ")\n",
    "\n",
    "# # Defining RoBERTa tokinizer\n",
    "# tokenizer = RobertaTokenizer.from_pretrained(\n",
    "#     roberta, \n",
    "#     do_lower_case=True, \n",
    "#     add_special_tokens=True,\n",
    "#     max_length=128, \n",
    "#     pad_to_max_length=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "distil_bert = 'distilbert-base-uncased'\n",
    "\n",
    "config = DistilBertConfig(dropout=0.2, attention_dropout=0.2)\n",
    "config.output_hidden_states = False\n",
    "transformer_model = TFDistilBertModel.from_pretrained(distil_bert, config = config)\n",
    "\n",
    "input_ids_in = tf.keras.layers.Input(shape=(128,), name='input_token', dtype='int32')\n",
    "input_masks_in = tf.keras.layers.Input(shape=(128,), name='masked_token', dtype='int32') \n",
    "\n",
    "embedding_layer = transformer_model(input_ids_in, attention_mask=input_masks_in)[0]\n",
    "X = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(embedding_layer)\n",
    "X = tf.keras.layers.GlobalMaxPool1D()(X)\n",
    "X = tf.keras.layers.Dense(50, activation='relu')(X)\n",
    "X = tf.keras.layers.Dropout(0.2)(X)\n",
    "X = tf.keras.layers.Dense(6, activation='sigmoid')(X)\n",
    "model = tf.keras.Model(inputs=[input_ids_in, input_masks_in], outputs = X)\n",
    "\n",
    "for layer in model.layers[:3]:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_token (InputLayer)        [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masked_token (InputLayer)       [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_distil_bert_model_2 (TFDisti ((None, 128, 768),)  66362880    input_token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 128, 100)     327600      tf_distil_bert_model_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 100)          0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 50)           5050        global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 50)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 6)            306         dropout_57[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 66,695,836\n",
      "Trainable params: 332,956\n",
      "Non-trainable params: 66,362,880\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I cannot believet believe this is even possible, considering my career is so important to so many people. I hope this is possible for my career, as I believe that I am in need of another artist or someone who is capable of doing my work. But there is such a thing as a “professional art” and you should take care of yourself and your work. Your work is your professional art, and it is your business as an art company. It should be given to someone else, because it isn't your own. You will lose your license without properly taking care of yourself and your work. You could lose your license without properly taking care of yourself and your work.<eop> I feel horrible about this, because I want to make sure that everyone understands that I am absolutely right. I will always be a professional artist,\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "\n",
    "model = AutoModelWithLMHead.from_pretrained(\"xlnet-base-cased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
    "\n",
    "# Padding text helps XLNet with short prompts - proposed by Aman Rusia in https://github.com/rusiaaman/XLNet-gen#methodology\n",
    "PADDING_TEXT = \"\"\"\n",
    "Are you going to change yet again, shift your position according to the questions that are put to you, and say that \n",
    "the objections are not really directed at the place from which you are speaking? Are you going to declare yet again \n",
    "that you have never been what you have been reproached with being? Are you already preparing the way out that will \n",
    "enable you in your next book to spring up somewhere else and declare as you're now doing: no, no, I'm not where \n",
    "you are lying in wait for me, but over here, laughing at you?' 'What, do you imagine that I would take so much \n",
    "trouble and so much pleasure in writing, do you think that I would keep so persistently to my task, \n",
    "if I were not preparing – with a rather shaky hand – a labyrinth into which I can venture, into which I can move my \n",
    "discourse... in which I can lose myself and appear at last to eyes that I will never have to meet again. I am no \n",
    "doubt not the only one who writes in order to have no face. Do not ask who I am and do not ask me to remain the same: \n",
    "leave it to our bureaucrats and our police to see that our papers are in order. At least spare us their morality \n",
    "when we write. <eod> </s> <eos>\"\"\"\n",
    "\n",
    "prompt = \"I cannot believe\"\n",
    "inputs = tokenizer.encode(PADDING_TEXT + prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
    "\n",
    "prompt_length = len(tokenizer.decode(inputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True))\n",
    "outputs = model.generate(inputs, max_length=250, do_sample=True, top_p=0.95, top_k=60)\n",
    "generated = prompt + tokenizer.decode(outputs[0])[prompt_length:]\n",
    "\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
