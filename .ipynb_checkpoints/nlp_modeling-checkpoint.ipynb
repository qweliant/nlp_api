{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f1819e75c0749abae7c5efa5578637d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1625270765.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\")\n",
    "\n",
    "# OpenAI GPT-2\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "TRAIN_TEXT = \"\"\"One day I said to my self in my own thought ‘whom am I praying to or is  there  a  God  who  listens  to  me?’  At  this  thought  I  was  invaded  by  dead full sadness and I said: ‘In vain have I kept my own heart pure (as David says). Later on I thought of the words of the same David, ‘Is the  inventor  of  the  ear  unable  to  hear?’  and  I  said:  ‘who  is  it  thatprovided  me  with  an  ear  to  hear,  who  created  me  as  a  rational[being] and how have I come into this world? Where do I come from? Had  I  lived  before  the  creator  of  the  world,  I  would  have  known  the  beginning of my life and of the consciousness [of myself] that created me? Was I created by my own hands? But I didn’t exist before I was created. If I say that my father and my mother created me, then I must search for the creator of my parents and of the parents of my parents until they arrive at the first who were not created as we [are] but who came into this world in some other way without being generated. For if  they  themselves  have  been  created,  I  know  nothing  of  their  origin  unless I say, ‘he who created them from nothing most be an uncreated 2\n",
    "essence  who  is  and  will  be  for  all  centuries  [to  come]  the  lord  and  master  of  all  things,  without  beginning  or  end,  immutable,  whose  years cannot be numbered.’ And I said: ‘Therefore, there is a creator; else there would have been no creation. This creator who endowed us with the gifts of intelligence and reason, cannot he himself be without them?  For  he  created  us  as  intelligent  beings  from  the  abundance  of  this intelligence and the same one being comprehends all, creates all,is  almighty.’  And  I  used  to  say:  ‘my  creator  will  hear  me  if  I  pray  to  him,’  and  because  of  this  thought  I  felt  very  happy.\"\"\"\n",
    "prompt = summarizer(TRAIN_TEXT, max_length=250, min_length=30)[0]['summary_text']\n",
    "\n",
    "inputs = tokenizer.encode(\n",
    "    TRAIN_TEXT + prompt, add_special_tokens=False, return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "prompt_length = len(\n",
    "    tokenizer.decode(\n",
    "        inputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "    )\n",
    ")\n",
    "outputs = model.generate(\n",
    "    inputs, max_length=250, do_sample=True, top_p=0.95, top_k=60\n",
    ")\n",
    "generated = prompt + tokenizer.decode(outputs[0])[prompt_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../models/\"\n",
    "\n",
    "# Step 1: Save a model, configuration and vocabulary that you have fine-tuned\n",
    "\n",
    "# If we have a distributed model, save only the encapsulated model\n",
    "# (it was wrapped in PyTorch DistributedDataParallel or DataParallel)\n",
    "model_to_save = model.module if hasattr(model, 'module') else model\n",
    "\n",
    "# If we save using the predefined names, we can load using `from_pretrained`\n",
    "output_model_file = os.path.join(output_dir, WEIGHTS_NAME)\n",
    "output_config_file = os.path.join(output_dir, CONFIG_NAME)\n",
    "\n",
    "torch.save(model_to_save.state_dict(), output_model_file)\n",
    "model_to_save.config.to_json_file(output_config_file)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "# Step 2: Re-load the saved model and vocabulary\n",
    "\n",
    "# Example for a Bert model\n",
    "model = GPT2LMHeadModel.from_pretrained(output_dir)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(output_dir)  # Add specific options if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for person in list\n",
    "    for person2 i nlist\n",
    "        if person2 not person:\n",
    "            TRAIN_TEXT = \"\"\" \"\"\"\n",
    "            first = nlp.generate(TRAIN_TEXT, prompt)\n",
    "            prompt = nlp.summarize()\n",
    "            TRAIN_TEXT2 = \"\"\"  \"\"\"\n",
    "            second = nlp.generate(TRAIN_TEXT, prompt)\n",
    "            prompt2 = nlp.summarize()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/quotes.csv\"\n",
    "df = pd.read_csv(path)\n",
    "nlp = NLP()\n",
    "conversation = []\n",
    "convo = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'string' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-dd5df17d80ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"prompt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'string' is not defined"
     ]
    }
   ],
   "source": [
    "sting  = \n",
    "\" One day I said to my self in my own thought ‘whom am I praying to or is  there  a  God  who  listens  to  me?’  At  this  thought  I  was  invaded  by  dead full sadness and I said: \\\n",
    "‘In vain have I kept my own heart pure (as David says). Later on I thought of the words of the same David, ‘Is the  inventor  of  the  ear  unable  to  hear?’  \\\n",
    "and  I  said:  ‘who  is  it  thatprovided  me  with  an  ear  to  hear,  who  created  me  as  a  rational[being] and how have I come into this world? \\\n",
    "Where do I come from? Had  I  lived  before  the  creator  of  the  world,  I  would  have  known  the  beginning of my life and of the consciousness [of myself] \\\n",
    "that created me? Was I created by my own hands? But I didn’t exist before I was created. If I say that my father and my mother created me, \\\n",
    "then I must search for the creator of my parents and of the parents of my parents until they arrive at the first who were not created as we [are] \\\n",
    "but who came into this world in some other way without being generated. For if  they  themselves  have  been  created,  I  know  nothing  of  their  origin  unless I say, ‘he who created them from nothing most be an uncreated 2 \\\n",
    "essence  who  is  and  will  be  for  all  centuries  [to  come]  the  lord  and  master  of  all  things,  without  beginning  or  end,  immutable,  whose  years cannot be numbered.’ \\\n",
    "And I said: ‘Therefore, there is a creator; else there would have been no creation. This creator who endowed us with the gifts of intelligence and reason, \\\n",
    "cannot he himself be without them?  For  he  created  us  as  intelligent  beings  from  the  abundance  of  this intelligence and the same one being comprehends all, \\\n",
    "creates all,is  almighty.’  And  I  used  to  say:  ‘my  creator  will  hear  me  if  I  pray  to  him,’  and  because  of  this  thought  I  felt  very  ha\n",
    "\"\n",
    "\n",
    "\n",
    "nlp.generate(\"\",\"prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def modelin(actor_1,actor_2):\n",
    "    \"\"\"\n",
    "    generates a conversation between two actors\n",
    "    \"\"\"\n",
    "    nlp = NLP()\n",
    "    convo = {}\n",
    "    conversation = []\n",
    "    \n",
    "    # create initial text\n",
    "    text = nlp.generate(df.quote,\"\")\n",
    "    \n",
    "    # add text to list \n",
    "    conversation.append(text)\n",
    "    \n",
    "    # summerize text\n",
    "    prompt = nlp.summarize()\n",
    "    \n",
    "    # generate response from first question\n",
    "    text = nlp.generate(df.quote, prompt)\n",
    "    \n",
    "    # append response\n",
    "    conversation.append(text)\n",
    "    \n",
    "    i = 5\n",
    "    while i:\n",
    "        \n",
    "        # summerize text\n",
    "        prompt = nlp.summarize()\n",
    "        # generate next sequence training on generated text and prompt with summaryii\n",
    "        text = nlp.generate(conversation[-1], prompt)\n",
    "        conversation.append(text)\n",
    "        i-=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60da19c98d974d99b37926c26dece1f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1300.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43abcc2f39874142aaa448e61f401f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa61c88033b4bb49d79742e4efbc9e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "526535814e694d5fb8a0d6b51c1544da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1625270765.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, name_1 in enumerate(df.iloc[:,0]):\n",
    "    for j, name_2 in enumerate(df.iloc[:,0]):\n",
    "        if name_1 is name_2:\n",
    "            continue\n",
    "            \n",
    "        # print(name_1, name_2)\n",
    "        \n",
    "        # INITIALIZE START PROMPT\n",
    "        # print(df.iloc[i,1])\n",
    "        n = nlp.summarize(df.iloc[j,1])\n",
    "        conversation.append(n)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
